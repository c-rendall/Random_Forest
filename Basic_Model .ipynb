{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will look at how random forest works by analyzing the [NOAA Climate Data online tool](https://www.ncdc.noaa.gov/cdo-web/) for Seattle, WA.  Obviously we could just watch the Weather Channel, but we will pretend that it doesn't exist and we want to predict it using our random forest model.  Since our output is the next day's temperature, which is a continuous value, and since we have a dataset containing output labels associated with our features, this is a supervised regression problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Workflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset consists of NOAA weather data from Seattle, Washington over the 2016 calendar year.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>temp_2</th>\n",
       "      <th>temp_1</th>\n",
       "      <th>average</th>\n",
       "      <th>actual</th>\n",
       "      <th>forecast_noaa</th>\n",
       "      <th>forecast_acc</th>\n",
       "      <th>forecast_under</th>\n",
       "      <th>friend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45.6</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Sat</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "      <td>45.7</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sun</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>45.8</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>45.9</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Tues</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>46.0</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  week  temp_2  temp_1  average  actual  forecast_noaa  \\\n",
       "0  2016      1    1   Fri      45      45     45.6      45             43   \n",
       "1  2016      1    2   Sat      44      45     45.7      44             41   \n",
       "2  2016      1    3   Sun      45      44     45.8      41             43   \n",
       "3  2016      1    4   Mon      44      41     45.9      40             44   \n",
       "4  2016      1    5  Tues      41      40     46.0      44             46   \n",
       "\n",
       "   forecast_acc  forecast_under  friend  \n",
       "0            50              44      29  \n",
       "1            50              44      61  \n",
       "2            46              47      56  \n",
       "3            48              46      53  \n",
       "4            46              46      41  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('temps.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't be using `forecast_noaa`, `forecast_acc`, or `forecast_under`, so let's go ahead and get rid of those: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>temp_2</th>\n",
       "      <th>temp_1</th>\n",
       "      <th>average</th>\n",
       "      <th>actual</th>\n",
       "      <th>friend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45.6</td>\n",
       "      <td>45</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Sat</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "      <td>45.7</td>\n",
       "      <td>44</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sun</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>45.8</td>\n",
       "      <td>41</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>45.9</td>\n",
       "      <td>40</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Tues</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>46.0</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  week  temp_2  temp_1  average  actual  friend\n",
       "0  2016      1    1   Fri      45      45     45.6      45      29\n",
       "1  2016      1    2   Sat      44      45     45.7      44      61\n",
       "2  2016      1    3   Sun      45      44     45.8      41      56\n",
       "3  2016      1    4   Mon      44      41     45.9      40      53\n",
       "4  2016      1    5  Tues      41      40     46.0      44      41"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove forecast_noaa, forecast_acc, and forecast_under\n",
    "df.drop(['forecast_noaa', 'forecast_acc', 'forecast_under'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the DataFrame, we have the following columns:\n",
    "\n",
    "- **year**: All data points are days within 2016\n",
    "- **month**: Integer number for the month of each year\n",
    "- **day**: Integer number for the day of each month\n",
    "- **week**: The day of the week as an abbreviated string\n",
    "- **temp_2**: The maximum temperature two days prior\n",
    "- **temp_1**: The maximum temperature one day prior\n",
    "- **average**: The historical average maximum temperature on that day\n",
    "- **actual**: The actual maximum temperature measurement\n",
    "- **friend**: A friend's prediction, a random number ranging from 20 below the average to 20 above the average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Outliers/Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding any further into machine learning models, let's check if there are any outliers, missing values, or strange observations in the data.  First, let's check the shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(348, 9)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 366 days in 2016, we are missing 18 days.  If one looks through what is on the NOAA website, it is clear that these days were simply not recorded.  This is a only a small portion of our total number of days, and the pattern appears to be random, so we will not worry about it.  To check for outliers, let's look at the summary statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>temp_2</th>\n",
       "      <th>temp_1</th>\n",
       "      <th>average</th>\n",
       "      <th>actual</th>\n",
       "      <th>friend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>348.0</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6.477011</td>\n",
       "      <td>15.514368</td>\n",
       "      <td>62.652299</td>\n",
       "      <td>62.701149</td>\n",
       "      <td>59.760632</td>\n",
       "      <td>62.543103</td>\n",
       "      <td>60.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.498380</td>\n",
       "      <td>8.772982</td>\n",
       "      <td>12.165398</td>\n",
       "      <td>12.120542</td>\n",
       "      <td>10.527306</td>\n",
       "      <td>11.794146</td>\n",
       "      <td>15.626179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>49.975000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>47.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>58.200000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>69.025000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>77.400000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         year       month         day      temp_2      temp_1     average  \\\n",
       "count   348.0  348.000000  348.000000  348.000000  348.000000  348.000000   \n",
       "mean   2016.0    6.477011   15.514368   62.652299   62.701149   59.760632   \n",
       "std       0.0    3.498380    8.772982   12.165398   12.120542   10.527306   \n",
       "min    2016.0    1.000000    1.000000   35.000000   35.000000   45.100000   \n",
       "25%    2016.0    3.000000    8.000000   54.000000   54.000000   49.975000   \n",
       "50%    2016.0    6.000000   15.000000   62.500000   62.500000   58.200000   \n",
       "75%    2016.0   10.000000   23.000000   71.000000   71.000000   69.025000   \n",
       "max    2016.0   12.000000   31.000000  117.000000  117.000000   77.400000   \n",
       "\n",
       "           actual      friend  \n",
       "count  348.000000  348.000000  \n",
       "mean    62.543103   60.034483  \n",
       "std     11.794146   15.626179  \n",
       "min     35.000000   28.000000  \n",
       "25%     54.000000   47.750000  \n",
       "50%     62.500000   60.000000  \n",
       "75%     71.000000   71.000000  \n",
       "max     92.000000   95.000000  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year       0\n",
       "month      0\n",
       "day        0\n",
       "week       0\n",
       "temp_2     0\n",
       "temp_1     0\n",
       "average    0\n",
       "actual     0\n",
       "friend     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NA values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data looks ok, although in a more thorough project, I would probably spend more time checking for outliers in this section, especially if the data was not from a mostly clean source like NOAA.  So we will proceed and conclude that there are no obvious outliers or missing value issues in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can feed this data into a model, we will have to do a bit of preprocessing.  The first step will be one-hot encoding.  Since we have days of the week as one of our features, which is categorical, we will need to one-hot encode it.  We might be tempted to just assign a value of 1-7 or something for each day, but this inadvertently leads to the algorithm placing more importance on Sunday, since it would have a higher numerical value.  One-hot encoding takes a categorical feature with n classes and creates n new features in the dataset where each feature representing a parituclar class assigns a 1 to rows of the class and 0 to everything else.  So we end up adding more features to our dataset, but we are able to effectively represent a categorical feature.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>temp_2</th>\n",
       "      <th>temp_1</th>\n",
       "      <th>average</th>\n",
       "      <th>actual</th>\n",
       "      <th>friend</th>\n",
       "      <th>week_Fri</th>\n",
       "      <th>week_Mon</th>\n",
       "      <th>week_Sat</th>\n",
       "      <th>week_Sun</th>\n",
       "      <th>week_Thurs</th>\n",
       "      <th>week_Tues</th>\n",
       "      <th>week_Wed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45.6</td>\n",
       "      <td>45</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "      <td>45.7</td>\n",
       "      <td>44</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>45.8</td>\n",
       "      <td>41</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>45.9</td>\n",
       "      <td>40</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>46.0</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  temp_2  temp_1  average  actual  friend  week_Fri  \\\n",
       "0  2016      1    1      45      45     45.6      45      29         1   \n",
       "1  2016      1    2      44      45     45.7      44      61         0   \n",
       "2  2016      1    3      45      44     45.8      41      56         0   \n",
       "3  2016      1    4      44      41     45.9      40      53         0   \n",
       "4  2016      1    5      41      40     46.0      44      41         0   \n",
       "\n",
       "   week_Mon  week_Sat  week_Sun  week_Thurs  week_Tues  week_Wed  \n",
       "0         0         0         0           0          0         0  \n",
       "1         0         1         0           0          0         0  \n",
       "2         0         0         1           0          0         0  \n",
       "3         1         0         0           0          0         0  \n",
       "4         0         0         0           0          1         0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode date\n",
    "df = pd.get_dummies(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(348, 15)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our dataset now has 15 features instead of 9 and all columns are in numerical format. Let's now split the dataset into our target and features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "y = df['actual']\n",
    "X = df.drop('actual', axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also now split the X and y into training and test sets using a size of 0.75:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets with 25% validation size\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Establish a Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we implement our model, we want to first establish a baseline, which gives us a check on whether our model is beating a mediocre guess or not.  In this case, we can use the historical max temperature averages.  So this baseline is essentially the error we would get if we just predicted the average maximum temperature for all days.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average baseline error: 5.06\n"
     ]
    }
   ],
   "source": [
    "# Baseline predictions = historical averages\n",
    "baseline_preds = X_test['average']\n",
    "baseline_errors = abs(baseline_preds - y_test)\n",
    "print(f'Average baseline error: {round(np.mean(baseline_errors), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our baseline is around 5.06 degrees.  If we cannot beat that, our model is clearly not working as we hoped. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Train Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to go ahead and train our model with the final dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=1000, random_state=1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train random forest regressor with 1000 decision trees on our data\n",
    "rf = RandomForestRegressor(n_estimators=1000, random_state=1)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Make Predictions on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When performing regression, MSE and RMSE are often used as error metrics.  In our case, we will use mean absolute error, since we are interested in how far away our average prediction is from the actual value.  So let's compare our predictions with the real data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 3.86\n"
     ]
    }
   ],
   "source": [
    "# Predict values \n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "# Calculate absolute errors\n",
    "errors = abs(predictions - y_test)\n",
    "print(f'Mean absolute error: {round(np.mean(errors), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our average estimate is off by 3.86 degrees!  That is at least over a 1 degree improvement from the baseline.  This is over a 25% improvement from the baseline, so depending on the problem, this could be significant.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Determine Performance Metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's understand our predictions in a bigger context by calculating an average using mean average percentage error subtracted from 100%: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.95\n"
     ]
    }
   ],
   "source": [
    "# Mean average percentage error\n",
    "mape = 100 * (errors / y_test)\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print(f'Accuracy: {round(accuracy, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not too bad! This model predicts the next day's temperature to almost 94% accuracy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Model Interpretation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest is often regarded as a black box.  It is a complicated algorithm capable of detecting very complex patterns in data, which makes it a bit harder to dissect than something like simple linear regression.  To get under the hood of a random forest model, we can do two things: look at a single tree in the forest, and look at feature importances.  \n",
    "\n",
    "Starting with examining trees, we can look at any tree out of the many trees in our random forest model.  Here's an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out one tree from the forest\n",
    "tree = rf.estimators_[5]\n",
    "\n",
    "# Export the image to a dot file\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "\n",
    "# Use dot file to create a graph\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "\n",
    "# Write graph to a png file\n",
    "graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we can do is look at feature importances.  The feature importances are relative in the sense that they represent how much including a particular variable improves the prediction.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: temp_1               Importance: 0.68\n",
      "Variable: average              Importance: 0.21\n",
      "Variable: temp_2               Importance: 0.03\n",
      "Variable: friend               Importance: 0.03\n",
      "Variable: day                  Importance: 0.02\n",
      "Variable: month                Importance: 0.01\n",
      "Variable: year                 Importance: 0.0\n",
      "Variable: week_Fri             Importance: 0.0\n",
      "Variable: week_Mon             Importance: 0.0\n",
      "Variable: week_Sat             Importance: 0.0\n",
      "Variable: week_Sun             Importance: 0.0\n",
      "Variable: week_Thurs           Importance: 0.0\n",
      "Variable: week_Tues            Importance: 0.0\n",
      "Variable: week_Wed             Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance \n",
    "                          in zip(feature_list, importances)]\n",
    "\n",
    "# Sort the feature importances by most important\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print feature and importance\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see based off this that overwhelmingly, the most important predictor is `temp_1`, the max temperature the day before.  This makes sense, since the previous day's temperature is generally indicative of what tomorrow's temperature will be like.  The second most important feature was the historical average.  This makes sense also.  The days of the weak and the year have no importance at all, which also makes sense because we would not generally believe that a particular day is prone to a certain type of weather pattern than another day.  It is important to note, however, that much like the previous day in weather data is important, if we were looking at **climate** data on much longer time scales, we would NOT expect the year to have no importance, and in fact, much like `temp_1` in this, it would probably be the most important on longer time scales.  \n",
    "\n",
    "In future verions of this model, we can remove the unimportant features and the importance probably will not suffer.  In certain other models, such as SVM, we would use the RF feature importance values as a feature selection.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 3.92 degrees.\n",
      "Accuracy: 93.76 %.\n"
     ]
    }
   ],
   "source": [
    "# New random forest with only the two most important variables\n",
    "rf_most_important = RandomForestRegressor(n_estimators= 1000, random_state=42)\n",
    "\n",
    "# Extract the two most important features\n",
    "important_indices = [feature_list.index('temp_1'), feature_list.index('average')]\n",
    "train_important = X_train[['temp_1', 'average']]\n",
    "test_important = X_test[['temp_1', 'average']]\n",
    "\n",
    "# Train the random forest\n",
    "rf_most_important.fit(train_important, y_train)\n",
    "\n",
    "# Make predictions and determine the error\n",
    "predictions = rf_most_important.predict(test_important)\n",
    "errors = abs(predictions - y_test)\n",
    "\n",
    "# Display the performance metrics\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "mape = np.mean(100 * (errors / test_labels))\n",
    "accuracy = 100 - mape\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! We could've used ONLY two features and gotten almost the exact same accuracy as before.  So in conclusion, this was a basic implementation of the random forest algorithm in Python.  How could we improve this? We could try hyperparameter optimization, a different algorithm, or collect more data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
